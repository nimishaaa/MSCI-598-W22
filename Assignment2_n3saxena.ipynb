{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2-n3saxena.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/fuzhenxin/textstyletransferdata/master/sentiment/neg.txt\n",
        "!wget -q https://raw.githubusercontent.com/fuzhenxin/textstyletransferdata/master/sentiment/pos.txt\n",
        "!wget -q \"https://gist.githubusercontent.com/sebleier/554280/raw/7e0e4a1ce04c2bb7bd41089c9821dbcf6d0c786c/NLTK's%2520list%2520of%2520english%2520stopwords\""
      ],
      "metadata": {
        "id": "bMK2dKZY8nPq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFx8kpGn758I",
        "outputId": "4de823ad-62bc-4d28-d310-44923522f4cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_text = pd.read_csv(\"pos.txt\", delimiter='\\t')\n",
        "neg_text = pd.read_csv(\"neg.txt\", delimiter='\\t')"
      ],
      "metadata": {
        "id": "xVDOtpmy8ux_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_text.columns = ['text']\n",
        "pos_text['label'] = 1\n",
        "neg_text.columns = ['text']\n",
        "neg_text['label'] = 0"
      ],
      "metadata": {
        "id": "NogYbGLN9nOH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = pd.concat([pos_text, neg_text])\n",
        "corpus.reset_index(inplace=True)\n",
        "del corpus['index']"
      ],
      "metadata": {
        "id": "KN0Z2z9g9zpO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['text'] = corpus['text'].str.replace('[^\\w\\s]', '')\n",
        "corpus['text'] = corpus['text'].str.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2XSBJHu-Azf",
        "outputId": "9e7be4a6-efaf-4319-e02d-66583a3b2149"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus['text'] = corpus['text'].apply(word_tokenize)"
      ],
      "metadata": {
        "id": "cstB_001ADwj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nostopwords = corpus.copy()"
      ],
      "metadata": {
        "id": "Zx3ei3ZHAXGO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = []\n",
        "with open(\"NLTK's list of english stopwords\") as f:\n",
        "  for line in f:\n",
        "    stop_words.append(line.split('\\n')[0])"
      ],
      "metadata": {
        "id": "ql2n_AapAgmy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_nostopwords['text'] = corpus_nostopwords['text'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "corpus_nostopwords['text'] = corpus_nostopwords['text'].apply(lambda x: \" \".join(x))\n",
        "corpus['text'] = corpus['text'].apply(lambda x: \" \".join(x))\n",
        "corpus_nostopwords['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFlVYw1xA1YG",
        "outputId": "cd524d71-a5ef-42b5-b9ba-b9cc3bcd95ad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               already tried one recipe day receiving book\n",
              "1          bought zoku quick pop daughterr zoku quick maker\n",
              "2                                  loves fun make ice cream\n",
              "3                                               hoping came\n",
              "4                book emphasizes sweet dessert pops however\n",
              "                                ...                        \n",
              "799108           said whoa im gon na like gameunfortunately\n",
              "799109    towards end first third game became insanely d...\n",
              "799110    cases would finally find hiding point behind r...\n",
              "799111                              die die die die die die\n",
              "799112    well get pictureif dont like game usually put ...\n",
              "Name: text, Length: 799113, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(corpus_nostopwords['text'], corpus_nostopwords['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UjZAVt2VBE9w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigrams no stop words"
      ],
      "metadata": {
        "id": "wyh0IordG_Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test[:int(len(x_test) * 0.5)]\n",
        "x_val = x_test[int(len(x_test) * 0.5):]\n",
        "y_test = y_test[:int(len(y_test) * 0.5)]\n",
        "y_val = y_test[int(len(y_test) * 0.5):]\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "\n",
        "file_1 = 'mnb_uni_ns'\n",
        "\n",
        "with open(file_1, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)\n",
        "\n",
        "print(model.score(x_test_t, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYJ7AxVVBQdK",
        "outputId": "5b2fe116-5b59-4a7e-e537-9033e181aab7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8078087848829933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigrams no stop words"
      ],
      "metadata": {
        "id": "1u_LD2v3HDU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(ngram_range=(2, 2))\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "\n",
        "file_2 = 'mnb_bi_ns'\n",
        "with open(file_2, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)\n",
        "\n",
        "print(model.score(x_test_t, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tR-_Q2vChx_",
        "outputId": "13f66dac-fc36-4545-e727-25f7d0ca0381"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8242022275059442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram+Bigram no stop words\n"
      ],
      "metadata": {
        "id": "tZwPr2jpHG3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "\n",
        "file_3 = 'mnb_uni_bi_ns'\n",
        "with open(file_3, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)\n",
        "\n",
        "print(model.score(x_test_t, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPUg5IIqHO8M",
        "outputId": "81969682-9629-4a6d-f5f6-cd33446908bb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8320360405456139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram with stop words\n",
        "\n"
      ],
      "metadata": {
        "id": "GG0PQjtSHjZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(corpus['text'], corpus['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "x_test = x_test[:int(len(x_test) * 0.5)]\n",
        "x_val = x_test[int(len(x_test) * 0.5):]\n",
        "y_test = y_test[:int(len(y_test) * 0.5)]\n",
        "y_val = y_test[int(len(y_test) * 0.5):]\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "print(model.score(x_test_t, y_test))\n",
        "\n",
        "file_4 = 'mnb_uni'\n",
        "with open(file_4, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW25h5T6FjOQ",
        "outputId": "3be2b9df-8bd4-4034-8485-c89ea6031660"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8078737595575077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram with stop words"
      ],
      "metadata": {
        "id": "72ozLpaKIZfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(ngram_range=(2, 2))\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "\n",
        "file_5 = 'mnb_bi'\n",
        "with open(file_5, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)\n",
        "\n",
        "print(model.score(x_test_t, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCZLAraaHvyp",
        "outputId": "57cf2796-7a29-455b-d29e-8a08cd2d6679"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8248176095906696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram+Bigram with stop words\n"
      ],
      "metadata": {
        "id": "JLwDKH91IWdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
        "count_vect.fit(x_train)\n",
        "x_train_t = count_vect.transform(x_train)\n",
        "x_test_t = count_vect.transform(x_test)\n",
        "x_tval_t = count_vect.transform(x_val)\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train_t, y_train)\n",
        "\n",
        "file_6 = 'mnb_uni_bi'\n",
        "with open(file_6, 'wb') as f:\n",
        "  pickle.dump((model, count_vect), f)\n",
        "\n",
        "print(model.score(x_test_t, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXNyEmlZIiYJ",
        "outputId": "3aced936-9735-4de9-f8cb-92193d1041fb"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8319004892943399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning the model"
      ],
      "metadata": {
        "id": "6hnRSVsKIumo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)}\n",
        "grid_search = GridSearchCV(model, parameters)\n",
        "grid_search.fit(x_tval_t, y_val)\n",
        "\n",
        "grid_search.score(x_test_t, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PRDK8coIvoG",
        "outputId": "08b5b5c6-7112-4e25-b83e-2c81869a95ef"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8644867414999187"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}